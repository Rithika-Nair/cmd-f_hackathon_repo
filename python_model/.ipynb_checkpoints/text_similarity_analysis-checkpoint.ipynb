{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a8a9021-1216-44a1-826a-93b852d18195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.tokens import Doc\n",
    "# from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c4db437-5343-4341-86d9-bf4d5bfd002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7e909a-9f42-43c1-aefb-8eb05f2f2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read USER ANSWERS data from the JSON file\n",
    "with open('data.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Process each text using spaCy\n",
    "user_data = []\n",
    "for entry in data:\n",
    "    doc = nlp(entry['text'])\n",
    "    user_entry = {'id': entry['id'], 'text': doc}\n",
    "    user_data.append(user_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bdc1ac-5be5-4f4f-95ef-0bcc1fdb51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DATABASE data from the JSON file\n",
    "with open('dummy.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Process each text using spaCy\n",
    "database_data = []\n",
    "for entry in data:\n",
    "    ans_doc = nlp(entry['answer'])\n",
    "    qn_doc = nlp(entry['question'])\n",
    "    database_entry = {'id': entry['id'], 'question': qn_doc, 'answer': ans_doc}\n",
    "    database_data.append(database_entry)\n",
    "\n",
    "# Now processed_data contains the processed text from the JSON file\n",
    "# You can use the processed data for further analysis or similarity comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66b3e1d-f961-4d6b-bb7b-760ecb41b6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'text': France's capital is Paris},\n",
       " {'id': 2, 'text': William Shakespeare},\n",
       " {'id': 3, 'text': Saturn},\n",
       " {'id': 4, 'text': There are seven continents},\n",
       " {'id': 5, 'text': Avacado is the main ingredient.}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b98a24c3-4faa-4938-85f6-47e86d956495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'question': What is the capital of France?,\n",
       "  'answer': The capital of France is Paris.},\n",
       " {'id': 2,\n",
       "  'question': Who wrote 'Romeo and Juliet'?,\n",
       "  'answer': William Shakespeare wrote 'Romeo and Juliet'.},\n",
       " {'id': 3,\n",
       "  'question': What is the largest planet in our solar system?,\n",
       "  'answer': Jupiter is the largest planet in our solar system.},\n",
       " {'id': 4,\n",
       "  'question': How many continents are there on Earth?,\n",
       "  'answer': There are seven continents on Earth.},\n",
       " {'id': 5,\n",
       "  'question': What is the main ingredient in guacamole?,\n",
       "  'answer': The main ingredient in guacamole is avocado.}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "907d4b1a-305f-447a-af59-c41c8606aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords from the user_data and database_data - AN ATTEMPT TO INCREASE WORD SIMILARITY\n",
    "\n",
    "# Process the text for each answer in the user data\n",
    "for user_answer in user_data:\n",
    "    filtered_user_answer = []\n",
    "    filtered_db_answer = []\n",
    "    user_doc = nlp(user_answer[\"text\"])\n",
    "\n",
    "    # Removing stop words and storing it in filtered_user_answer which is stored in the filtered_answer key\n",
    "    for word in user_doc:\n",
    "        if word.is_stop==False:\n",
    "            filtered_user_answer.append(word)\n",
    "    \n",
    "    user_answer[\"filtered_user_answer\"] = filtered_user_answer\n",
    "    user_answer[\"filtered_user_answer\"] = ' '.join(token.text for token in user_answer[\"filtered_user_answer\"])\n",
    "\n",
    "    # Find the corresponding entry in database_data based on 'id'\n",
    "    db_answer = next((item for item in database_data if item[\"id\"] == user_answer[\"id\"]), None)\n",
    "\n",
    "    if db_answer:\n",
    "        database_doc = nlp(db_answer[\"answer\"])\n",
    "        # Removing stop words and storing it in filtered_user_answer which is stored in the filtered_answer key\n",
    "        for word in database_doc:\n",
    "            if word.is_stop==False:\n",
    "                filtered_db_answer.append(word)\n",
    "        \n",
    "        db_answer[\"filtered_db_answer\"] = filtered_db_answer\n",
    "        db_answer[\"filtered_db_answer\"] = ' '.join(token.text for token in db_answer[\"filtered_db_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05e51290-184b-4554-b6cb-743613f3341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing words from the user_answer and database_answer that is also from the database_question\n",
    "\n",
    "# Process the text for each answer in the user data\n",
    "for user_answer in user_data:\n",
    "    final_user_answer = []\n",
    "    final_db_answer = []\n",
    "    user_doc = nlp(user_answer[\"filtered_user_answer\"])\n",
    "\n",
    "    # Find the corresponding entry in database_data based on 'id'\n",
    "    db_answer = next((item for item in database_data if item[\"id\"] == user_answer[\"id\"]), None)\n",
    "\n",
    "    if db_answer:\n",
    "        db_qn_doc = nlp(db_answer[\"question\"])\n",
    "        db_ans_doc = nlp(db_answer[\"filtered_db_answer\"])\n",
    "        \n",
    "        qn_words_list = [token.text for token in db_qn_doc]\n",
    "        for word in db_ans_doc:\n",
    "            if not (word.text in qn_words_list):\n",
    "                if not (word.text in final_db_answer):\n",
    "                    final_db_answer.append(word)\n",
    "\n",
    "        for word in user_doc:\n",
    "            if not (word.text in qn_words_list):\n",
    "                if not (word.text in final_user_answer):\n",
    "                    final_user_answer.append(word)\n",
    "        \n",
    "        db_answer[\"final_answer\"] = final_db_answer\n",
    "        db_answer[\"final_answer\"] = ' '.join(token.text for token in db_answer[\"final_answer\"] if not token.is_punct)\n",
    "\n",
    "        user_answer[\"final_answer\"] = final_user_answer\n",
    "        user_answer[\"final_answer\"] = ' '.join(token.text for token in user_answer[\"final_answer\"] if not token.is_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cf6e3d3-d005-425a-9f72-8de15b3797e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # removing words from the database answer that are contained in the database question - AN ATTEMPT TO INCREASE WORD SIMILARITY\n",
    "# for db_answer in database_data:\n",
    "#     final_answer = []\n",
    "#     db_qn_doc = nlp(db_answer[\"question\"])\n",
    "#     db_ans_doc = nlp(db_answer[\"filtered_db_answer\"])\n",
    "\n",
    "#     # for avoid in db_qn_doc:\n",
    "#     #     for word in db_ans_doc:\n",
    "#     #         if (word != avoid):\n",
    "#     #             if not (word in final_answer) :\n",
    "#     #                 final_answer.append(word)\n",
    "\n",
    "#     qn_words_list = [token.text for token in db_qn_doc]\n",
    "#     for word in db_ans_doc:\n",
    "#         if not (word.text in qn_words_list):\n",
    "#             if not (word.text in final_answer):\n",
    "#                 final_answer.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed970ee0-c26c-4805-8a8a-324b9d8bc09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p5/hwwszq5n2kv_18jljl_3nq1h0000gn/T/ipykernel_4472/3934491858.py:3: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  return user_doc.similarity(database_doc)\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate similarity between two documents\n",
    "def calculate_similarity(user_doc, database_doc):\n",
    "    return user_doc.similarity(database_doc)\n",
    "\n",
    "# Process the text for each answer in the user data\n",
    "for user_answer in user_data:\n",
    "    user_doc = nlp(user_answer[\"final_answer\"])\n",
    "\n",
    "    # Find the corresponding entry in database_data based on 'id'\n",
    "    db_answer = next((item for item in database_data if item[\"id\"] == user_answer[\"id\"]), None)\n",
    "\n",
    "    if db_answer:\n",
    "        database_doc = nlp(db_answer[\"final_answer\"])\n",
    "\n",
    "        # Calculate similarity\n",
    "        similarity_score = calculate_similarity(user_doc, database_doc)\n",
    "\n",
    "        # Store the similarity score or use it as needed\n",
    "        user_answer[\"similarity_score\"] = similarity_score\n",
    "\n",
    "# Now user_data contains similarity scores for each corresponding pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6537c0a7-281f-4e00-b7ef-9129f3419b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'text': France's capital is Paris,\n",
       "  'filtered_user_answer': 'France capital Paris',\n",
       "  'final_answer': 'Paris',\n",
       "  'similarity_score': 1.0},\n",
       " {'id': 2,\n",
       "  'text': William Shakespeare,\n",
       "  'filtered_user_answer': 'William Shakespeare',\n",
       "  'final_answer': 'William Shakespeare',\n",
       "  'similarity_score': 1.0},\n",
       " {'id': 3,\n",
       "  'text': Saturn,\n",
       "  'filtered_user_answer': 'Saturn',\n",
       "  'final_answer': 'Saturn',\n",
       "  'similarity_score': 0.7763198775373695},\n",
       " {'id': 4,\n",
       "  'text': There are seven continents,\n",
       "  'filtered_user_answer': 'seven continents',\n",
       "  'final_answer': 'seven',\n",
       "  'similarity_score': 1.0},\n",
       " {'id': 5,\n",
       "  'text': Avacado is the main ingredient.,\n",
       "  'filtered_user_answer': 'Avacado main ingredient .',\n",
       "  'final_answer': 'Avacado',\n",
       "  'similarity_score': 0.0}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67d5e2a3-39d1-4565-8de9-29ed1d881b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'question': What is the capital of France?,\n",
       "  'answer': The capital of France is Paris.,\n",
       "  'filtered_db_answer': 'capital France Paris .',\n",
       "  'final_answer': 'Paris'},\n",
       " {'id': 2,\n",
       "  'question': Who wrote 'Romeo and Juliet'?,\n",
       "  'answer': William Shakespeare wrote 'Romeo and Juliet'.,\n",
       "  'filtered_db_answer': \"William Shakespeare wrote ' Romeo Juliet ' .\",\n",
       "  'final_answer': 'William Shakespeare'},\n",
       " {'id': 3,\n",
       "  'question': What is the largest planet in our solar system?,\n",
       "  'answer': Jupiter is the largest planet in our solar system.,\n",
       "  'filtered_db_answer': 'Jupiter largest planet solar system .',\n",
       "  'final_answer': 'Jupiter'},\n",
       " {'id': 4,\n",
       "  'question': How many continents are there on Earth?,\n",
       "  'answer': There are seven continents on Earth.,\n",
       "  'filtered_db_answer': 'seven continents Earth .',\n",
       "  'final_answer': 'seven'},\n",
       " {'id': 5,\n",
       "  'question': What is the main ingredient in guacamole?,\n",
       "  'answer': The main ingredient in guacamole is avocado.,\n",
       "  'filtered_db_answer': 'main ingredient guacamole avocado .',\n",
       "  'final_answer': 'avocado'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57b9ac79-259c-4b73-8e8b-50124eca734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the average of the scores\n",
    "user_similarity = 0\n",
    "\n",
    "for user_entry in user_data:\n",
    "    user_similarity += user_entry[\"similarity_score\"] # You can access similarity scores using user_data[i][\"similarity_score\"]\n",
    "\n",
    "avg_score = user_similarity/len(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb2842c7-69ef-4f66-b8ba-5dad909d2b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing similarity scores into json file\n",
    "with open(\"user_final_score.json\", \"w\") as write_file:\n",
    "    json.dump(avg_score, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b360b-ef7a-4414-928c-6e03e335716d",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
